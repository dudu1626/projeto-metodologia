Iniciando treinamento...
______________________________________________________________________________________________________
Treinando modelo 1/10
Época 1, Perda Treino: 1.3653, Acurácia Treino: 0.5409
Época 1, Perda Validação: 0.8761, Acurácia Validação: 0.7392
Época 2, Perda Treino: 0.6863, Acurácia Treino: 0.7645
Época 2, Perda Validação: 0.6190, Acurácia Validação: 0.7840
Época 3, Perda Treino: 0.5897, Acurácia Treino: 0.7936
Época 3, Perda Validação: 0.5732, Acurácia Validação: 0.8045
Parada antecipada: Acurácia de validação (0.8045) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 1: Média Perda Treino: 0.5897, Média Acurácia Treino: 0.7936, Média Perda Validação: 0.5732, Média Acurácia Validação: 0.8045
Tempo médio de treino: 57.523687
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 149.529 W
Emissões médias: 0.00014500555042562457 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 2/10
Época 1, Perda Treino: 1.3651, Acurácia Treino: 0.5447
Época 1, Perda Validação: 0.8611, Acurácia Validação: 0.7536
Época 2, Perda Treino: 0.6636, Acurácia Treino: 0.7755
Época 2, Perda Validação: 0.5941, Acurácia Validação: 0.7973
Época 3, Perda Treino: 0.5686, Acurácia Treino: 0.8033
Época 3, Perda Validação: 0.5474, Acurácia Validação: 0.8131
Parada antecipada: Acurácia de validação (0.8131) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 2: Média Perda Treino: 0.5791, Média Acurácia Treino: 0.7984, Média Perda Validação: 0.5603, Média Acurácia Validação: 0.8088
Tempo médio de treino: 57.395534
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 149.7975 W
Emissões médias: 0.0001454383885786017 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 3/10
Época 1, Perda Treino: 1.3497, Acurácia Treino: 0.5525
Época 1, Perda Validação: 0.8708, Acurácia Validação: 0.7485
Época 2, Perda Treino: 0.6824, Acurácia Treino: 0.7715
Época 2, Perda Validação: 0.6169, Acurácia Validação: 0.7822
Época 3, Perda Treino: 0.5878, Acurácia Treino: 0.7963
Época 3, Perda Validação: 0.5724, Acurácia Validação: 0.7980
Época 4, Perda Treino: 0.5395, Acurácia Treino: 0.8147
Época 4, Perda Validação: 0.5211, Acurácia Validação: 0.8179
Parada antecipada: Acurácia de validação (0.8179) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 4
Modelo 3: Média Perda Treino: 0.5659, Média Acurácia Treino: 0.8039, Média Perda Validação: 0.5472, Média Acurácia Validação: 0.8118
Tempo médio de treino: 63.671875
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 174.9286666666667 W
Emissões médias: 0.00016098173569897565 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 4/10
Época 1, Perda Treino: 1.3368, Acurácia Treino: 0.5569
Época 1, Perda Validação: 0.8387, Acurácia Validação: 0.7558
Época 2, Perda Treino: 0.6573, Acurácia Treino: 0.7749
Época 2, Perda Validação: 0.5938, Acurácia Validação: 0.7947
Época 3, Perda Treino: 0.5648, Acurácia Treino: 0.8037
Época 3, Perda Validação: 0.5368, Acurácia Validação: 0.8146
Parada antecipada: Acurácia de validação (0.8146) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 4: Média Perda Treino: 0.5656, Média Acurácia Treino: 0.8038, Média Perda Validação: 0.5446, Média Acurácia Validação: 0.8125
Tempo médio de treino: 62.07698
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 168.71475 W
Emissões médias: 0.00015670172866287014 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 5/10
Época 1, Perda Treino: 1.3709, Acurácia Treino: 0.5378
Época 1, Perda Validação: 0.8803, Acurácia Validação: 0.7482
Época 2, Perda Treino: 0.6787, Acurácia Treino: 0.7709
Época 2, Perda Validação: 0.6319, Acurácia Validação: 0.7853
Época 3, Perda Treino: 0.5823, Acurácia Treino: 0.7996
Época 3, Perda Validação: 0.5522, Acurácia Validação: 0.8094
Parada antecipada: Acurácia de validação (0.8094) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 5: Média Perda Treino: 0.5690, Média Acurácia Treino: 0.8030, Média Perda Validação: 0.5461, Média Acurácia Validação: 0.8119
Tempo médio de treino: 61.113991799999994
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 165.14360000000002 W
Emissões médias: 0.0001542460438080131 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 6/10
Época 1, Perda Treino: 1.3469, Acurácia Treino: 0.5529
Época 1, Perda Validação: 0.8461, Acurácia Validação: 0.7518
Época 2, Perda Treino: 0.6659, Acurácia Treino: 0.7703
Época 2, Perda Validação: 0.6108, Acurácia Validação: 0.7830
Época 3, Perda Treino: 0.5771, Acurácia Treino: 0.7955
Época 3, Perda Validação: 0.5657, Acurácia Validação: 0.7948
Época 4, Perda Treino: 0.5336, Acurácia Treino: 0.8127
Época 4, Perda Validação: 0.5175, Acurácia Validação: 0.8213
Parada antecipada: Acurácia de validação (0.8213) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 4
Modelo 6: Média Perda Treino: 0.5631, Média Acurácia Treino: 0.8046, Média Perda Validação: 0.5414, Média Acurácia Validação: 0.8135
Tempo médio de treino: 63.656529666666664
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 174.0785 W
Emissões médias: 0.00016050246891965062 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 7/10
Época 1, Perda Treino: 1.3512, Acurácia Treino: 0.5468
Época 1, Perda Validação: 0.8675, Acurácia Validação: 0.7421
Época 2, Perda Treino: 0.6849, Acurácia Treino: 0.7651
Época 2, Perda Validação: 0.6129, Acurácia Validação: 0.7867
Época 3, Perda Treino: 0.5846, Acurácia Treino: 0.7973
Época 3, Perda Validação: 0.5518, Acurácia Validação: 0.8065
Parada antecipada: Acurácia de validação (0.8065) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 7: Média Perda Treino: 0.5661, Média Acurácia Treino: 0.8035, Média Perda Validação: 0.5429, Média Acurácia Validação: 0.8125
Tempo médio de treino: 62.738339142857136
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 170.23700000000002 W
Emissões médias: 0.00015822403465472619 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 8/10
Época 1, Perda Treino: 1.3746, Acurácia Treino: 0.5459
Época 1, Perda Validação: 0.8546, Acurácia Validação: 0.7498
Época 2, Perda Treino: 0.6597, Acurácia Treino: 0.7745
Época 2, Perda Validação: 0.5943, Acurácia Validação: 0.7933
Época 3, Perda Treino: 0.5648, Acurácia Treino: 0.8032
Época 3, Perda Validação: 0.5512, Acurácia Validação: 0.8097
Parada antecipada: Acurácia de validação (0.8097) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 8: Média Perda Treino: 0.5660, Média Acurácia Treino: 0.8035, Média Perda Validação: 0.5439, Média Acurácia Validação: 0.8121
Tempo médio de treino: 62.044046875
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 167.85399999999998 W
Emissões médias: 0.0001565758592273878 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 9/10
Época 1, Perda Treino: 1.3528, Acurácia Treino: 0.5429
Época 1, Perda Validação: 0.8608, Acurácia Validação: 0.7559
Época 2, Perda Treino: 0.6672, Acurácia Treino: 0.7762
Época 2, Perda Validação: 0.6017, Acurácia Validação: 0.7877
Época 3, Perda Treino: 0.5702, Acurácia Treino: 0.8020
Época 3, Perda Validação: 0.5541, Acurácia Validação: 0.8046
Parada antecipada: Acurácia de validação (0.8046) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 9: Média Perda Treino: 0.5664, Média Acurácia Treino: 0.8033, Média Perda Validação: 0.5450, Média Acurácia Validação: 0.8113
Tempo médio de treino: 61.528347000000004
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 165.68422222222222 W
Emissões médias: 0.00015534585722584807 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 10/10
Época 1, Perda Treino: 1.3661, Acurácia Treino: 0.5460
Época 1, Perda Validação: 0.8668, Acurácia Validação: 0.7505
Época 2, Perda Treino: 0.6747, Acurácia Treino: 0.7703
Época 2, Perda Validação: 0.6106, Acurácia Validação: 0.7913
Época 3, Perda Treino: 0.5802, Acurácia Treino: 0.7998
Época 3, Perda Validação: 0.5550, Acurácia Validação: 0.8093
Parada antecipada: Acurácia de validação (0.8093) atingiu ou excedeu a acurácia alvo da GoogLeNet (0.8000) na época 3
Modelo 10: Média Perda Treino: 0.5678, Média Acurácia Treino: 0.8030, Média Perda Validação: 0.5460, Média Acurácia Validação: 0.8111
Tempo médio de treino: 61.09585460000001
FLOPs: 104332160.0
Parâmetros: 533402.0
Consumo médio de energia: 163.8337 W
Emissões médias: 0.0001541959259299965 kg CO₂
************************************************************************************************
O melhor modelo é o Modelo_6 com a maior média de acurácia de validação: 0.8135
************************************************************************************************
Tempo Médio de Treino: 61.09585460000001 segundos
Consumo Médio de Energia: nan W
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 28, 28]             640
       BatchNorm2d-2           [-1, 64, 28, 28]             128
              ReLU-3           [-1, 64, 28, 28]               0
         MaxPool2d-4           [-1, 64, 14, 14]               0
            Conv2d-5           [-1, 64, 14, 14]           4,160
       BatchNorm2d-6           [-1, 64, 14, 14]             128
              ReLU-7           [-1, 64, 14, 14]               0
            Conv2d-8           [-1, 96, 14, 14]           6,240
       BatchNorm2d-9           [-1, 96, 14, 14]             192
             ReLU-10           [-1, 96, 14, 14]               0
           Conv2d-11          [-1, 128, 14, 14]         110,720
      BatchNorm2d-12          [-1, 128, 14, 14]             256
             ReLU-13          [-1, 128, 14, 14]               0
           Conv2d-14           [-1, 16, 14, 14]           1,040
      BatchNorm2d-15           [-1, 16, 14, 14]              32
             ReLU-16           [-1, 16, 14, 14]               0
           Conv2d-17           [-1, 32, 14, 14]          12,832
      BatchNorm2d-18           [-1, 32, 14, 14]              64
             ReLU-19           [-1, 32, 14, 14]               0
        MaxPool2d-20           [-1, 64, 14, 14]               0
           Conv2d-21           [-1, 32, 14, 14]           2,080
      BatchNorm2d-22           [-1, 32, 14, 14]              64
             ReLU-23           [-1, 32, 14, 14]               0
  InceptionModule-24          [-1, 256, 14, 14]               0
           Conv2d-25          [-1, 128, 14, 14]          32,896
      BatchNorm2d-26          [-1, 128, 14, 14]             256
             ReLU-27          [-1, 128, 14, 14]               0
           Conv2d-28          [-1, 128, 14, 14]          32,896
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
           Conv2d-31          [-1, 192, 14, 14]         221,376
      BatchNorm2d-32          [-1, 192, 14, 14]             384
             ReLU-33          [-1, 192, 14, 14]               0
           Conv2d-34           [-1, 32, 14, 14]           8,224
      BatchNorm2d-35           [-1, 32, 14, 14]              64
             ReLU-36           [-1, 32, 14, 14]               0
           Conv2d-37           [-1, 96, 14, 14]          76,896
      BatchNorm2d-38           [-1, 96, 14, 14]             192
             ReLU-39           [-1, 96, 14, 14]               0
        MaxPool2d-40          [-1, 256, 14, 14]               0
           Conv2d-41           [-1, 64, 14, 14]          16,448
      BatchNorm2d-42           [-1, 64, 14, 14]             128
             ReLU-43           [-1, 64, 14, 14]               0
  InceptionModule-44          [-1, 480, 14, 14]               0
        MaxPool2d-45            [-1, 480, 7, 7]               0
AdaptiveAvgPool2d-46            [-1, 480, 1, 1]               0
          Dropout-47                  [-1, 480]               0
           Linear-48                   [-1, 10]           4,810
================================================================
Total params: 533,402
Trainable params: 533,402
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 7.53
Params size (MB): 2.03
Estimated Total Size (MB): 9.57
----------------------------------------------------------------
