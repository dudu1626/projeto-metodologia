Iniciando treinamento...
______________________________________________________________________________________________________
Treinando modelo 1/10
Época 1, Perda Treino: 0.6289, Acurácia Treino: 0.7776
Época 1, Perda Validação: 0.4128, Acurácia Validação: 0.8484
Parada antecipada: Acurácia de validação (0.8484) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 1: Média Perda Treino: 0.6289, Média Acurácia Treino: 0.7776, Média Perda Validação: 0.4128, Média Acurácia Validação: 0.8484
Tempo médio de treino: 92.687738
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002444497473245525 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 2/10
Época 1, Perda Treino: 0.6419, Acurácia Treino: 0.7725
Época 1, Perda Validação: 0.3880, Acurácia Validação: 0.8528
Parada antecipada: Acurácia de validação (0.8528) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 2: Média Perda Treino: 0.6354, Média Acurácia Treino: 0.7751, Média Perda Validação: 0.4004, Média Acurácia Validação: 0.8506
Tempo médio de treino: 92.64089200000001
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002441048529361763 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 3/10
Época 1, Perda Treino: 0.6123, Acurácia Treino: 0.7819
Época 1, Perda Validação: 0.3699, Acurácia Validação: 0.8618
Parada antecipada: Acurácia de validação (0.8618) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 3: Média Perda Treino: 0.6277, Média Acurácia Treino: 0.7773, Média Perda Validação: 0.3902, Média Acurácia Validação: 0.8543
Tempo médio de treino: 92.64948533333335
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002446301253459685 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 4/10
Época 1, Perda Treino: 0.6342, Acurácia Treino: 0.7757
Época 1, Perda Validação: 0.3997, Acurácia Validação: 0.8522
Parada antecipada: Acurácia de validação (0.8522) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 4: Média Perda Treino: 0.6293, Média Acurácia Treino: 0.7769, Média Perda Validação: 0.3926, Média Acurácia Validação: 0.8538
Tempo médio de treino: 92.64350875000001
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002446214589604893 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 5/10
Época 1, Perda Treino: 0.6211, Acurácia Treino: 0.7799
Época 1, Perda Validação: 0.3762, Acurácia Validação: 0.8614
Parada antecipada: Acurácia de validação (0.8614) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 5: Média Perda Treino: 0.6277, Média Acurácia Treino: 0.7775, Média Perda Validação: 0.3893, Média Acurácia Validação: 0.8553
Tempo médio de treino: 92.64001520000001
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002449578212000788 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 6/10
Época 1, Perda Treino: 0.6356, Acurácia Treino: 0.7759
Época 1, Perda Validação: 0.3753, Acurácia Validação: 0.8597
Parada antecipada: Acurácia de validação (0.8597) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 6: Média Perda Treino: 0.6290, Média Acurácia Treino: 0.7773, Média Perda Validação: 0.3870, Média Acurácia Validação: 0.8561
Tempo médio de treino: 92.65236399999999
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002451758834761247 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 7/10
Época 1, Perda Treino: 0.6310, Acurácia Treino: 0.7766
Época 1, Perda Validação: 0.3759, Acurácia Validação: 0.8624
Parada antecipada: Acurácia de validação (0.8624) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 7: Média Perda Treino: 0.6293, Média Acurácia Treino: 0.7772, Média Perda Validação: 0.3854, Média Acurácia Validação: 0.8570
Tempo médio de treino: 92.65484714285715
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.00024516017857724546 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 8/10
Época 1, Perda Treino: 0.6237, Acurácia Treino: 0.7776
Época 1, Perda Validação: 0.3869, Acurácia Validação: 0.8570
Parada antecipada: Acurácia de validação (0.8570) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 8: Média Perda Treino: 0.6286, Média Acurácia Treino: 0.7772, Média Perda Validação: 0.3856, Média Acurácia Validação: 0.8570
Tempo médio de treino: 92.65201837500001
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002450872872151956 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 9/10
Época 1, Perda Treino: 0.6236, Acurácia Treino: 0.7790
Época 1, Perda Validação: 0.3772, Acurácia Validação: 0.8628
Parada antecipada: Acurácia de validação (0.8628) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 9: Média Perda Treino: 0.6280, Média Acurácia Treino: 0.7774, Média Perda Validação: 0.3846, Média Acurácia Validação: 0.8576
Tempo médio de treino: 92.65657411111113
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.0002450600156802483 kg CO₂
______________________________________________________________________________________________________
Treinando modelo 10/10
Época 1, Perda Treino: 0.6227, Acurácia Treino: 0.7784
Época 1, Perda Validação: 0.3747, Acurácia Validação: 0.8619
Parada antecipada: Acurácia de validação (0.8619) atingiu ou excedeu a acurácia alvo da ResNet (0.8000) na época 1
Modelo 10: Média Perda Treino: 0.6275, Média Acurácia Treino: 0.7775, Média Perda Validação: 0.3836, Média Acurácia Validação: 0.8580
Tempo médio de treino: 92.65447550000002
FLOPs: 939116032.0
Parâmetros: 21280970.0
Consumo médio de energia: 0.0 W
Emissões médias: 0.00024502679013460935 kg CO₂
************************************************************************************************
O melhor modelo é o Modelo_10 com a maior média de acurácia de validação: 0.8580
************************************************************************************************
Tempo Médio de Treino: 92.65447550000002 segundos
Consumo Médio de Energia: nan W
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 28, 28]             576
       BatchNorm2d-2           [-1, 64, 28, 28]             128
              ReLU-3           [-1, 64, 28, 28]               0
            Conv2d-4           [-1, 64, 28, 28]          36,864
       BatchNorm2d-5           [-1, 64, 28, 28]             128
              ReLU-6           [-1, 64, 28, 28]               0
            Conv2d-7           [-1, 64, 28, 28]          36,864
       BatchNorm2d-8           [-1, 64, 28, 28]             128
              ReLU-9           [-1, 64, 28, 28]               0
       BasicBlock-10           [-1, 64, 28, 28]               0
           Conv2d-11           [-1, 64, 28, 28]          36,864
      BatchNorm2d-12           [-1, 64, 28, 28]             128
             ReLU-13           [-1, 64, 28, 28]               0
           Conv2d-14           [-1, 64, 28, 28]          36,864
      BatchNorm2d-15           [-1, 64, 28, 28]             128
             ReLU-16           [-1, 64, 28, 28]               0
       BasicBlock-17           [-1, 64, 28, 28]               0
           Conv2d-18           [-1, 64, 28, 28]          36,864
      BatchNorm2d-19           [-1, 64, 28, 28]             128
             ReLU-20           [-1, 64, 28, 28]               0
           Conv2d-21           [-1, 64, 28, 28]          36,864
      BatchNorm2d-22           [-1, 64, 28, 28]             128
             ReLU-23           [-1, 64, 28, 28]               0
       BasicBlock-24           [-1, 64, 28, 28]               0
           Conv2d-25          [-1, 128, 14, 14]          73,728
      BatchNorm2d-26          [-1, 128, 14, 14]             256
             ReLU-27          [-1, 128, 14, 14]               0
           Conv2d-28          [-1, 128, 14, 14]         147,456
      BatchNorm2d-29          [-1, 128, 14, 14]             256
           Conv2d-30          [-1, 128, 14, 14]           8,192
      BatchNorm2d-31          [-1, 128, 14, 14]             256
             ReLU-32          [-1, 128, 14, 14]               0
       BasicBlock-33          [-1, 128, 14, 14]               0
           Conv2d-34          [-1, 128, 14, 14]         147,456
      BatchNorm2d-35          [-1, 128, 14, 14]             256
             ReLU-36          [-1, 128, 14, 14]               0
           Conv2d-37          [-1, 128, 14, 14]         147,456
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
       BasicBlock-40          [-1, 128, 14, 14]               0
           Conv2d-41          [-1, 128, 14, 14]         147,456
      BatchNorm2d-42          [-1, 128, 14, 14]             256
             ReLU-43          [-1, 128, 14, 14]               0
           Conv2d-44          [-1, 128, 14, 14]         147,456
      BatchNorm2d-45          [-1, 128, 14, 14]             256
             ReLU-46          [-1, 128, 14, 14]               0
       BasicBlock-47          [-1, 128, 14, 14]               0
           Conv2d-48          [-1, 128, 14, 14]         147,456
      BatchNorm2d-49          [-1, 128, 14, 14]             256
             ReLU-50          [-1, 128, 14, 14]               0
           Conv2d-51          [-1, 128, 14, 14]         147,456
      BatchNorm2d-52          [-1, 128, 14, 14]             256
             ReLU-53          [-1, 128, 14, 14]               0
       BasicBlock-54          [-1, 128, 14, 14]               0
           Conv2d-55            [-1, 256, 7, 7]         294,912
      BatchNorm2d-56            [-1, 256, 7, 7]             512
             ReLU-57            [-1, 256, 7, 7]               0
           Conv2d-58            [-1, 256, 7, 7]         589,824
      BatchNorm2d-59            [-1, 256, 7, 7]             512
           Conv2d-60            [-1, 256, 7, 7]          32,768
      BatchNorm2d-61            [-1, 256, 7, 7]             512
             ReLU-62            [-1, 256, 7, 7]               0
       BasicBlock-63            [-1, 256, 7, 7]               0
           Conv2d-64            [-1, 256, 7, 7]         589,824
      BatchNorm2d-65            [-1, 256, 7, 7]             512
             ReLU-66            [-1, 256, 7, 7]               0
           Conv2d-67            [-1, 256, 7, 7]         589,824
      BatchNorm2d-68            [-1, 256, 7, 7]             512
             ReLU-69            [-1, 256, 7, 7]               0
       BasicBlock-70            [-1, 256, 7, 7]               0
           Conv2d-71            [-1, 256, 7, 7]         589,824
      BatchNorm2d-72            [-1, 256, 7, 7]             512
             ReLU-73            [-1, 256, 7, 7]               0
           Conv2d-74            [-1, 256, 7, 7]         589,824
      BatchNorm2d-75            [-1, 256, 7, 7]             512
             ReLU-76            [-1, 256, 7, 7]               0
       BasicBlock-77            [-1, 256, 7, 7]               0
           Conv2d-78            [-1, 256, 7, 7]         589,824
      BatchNorm2d-79            [-1, 256, 7, 7]             512
             ReLU-80            [-1, 256, 7, 7]               0
           Conv2d-81            [-1, 256, 7, 7]         589,824
      BatchNorm2d-82            [-1, 256, 7, 7]             512
             ReLU-83            [-1, 256, 7, 7]               0
       BasicBlock-84            [-1, 256, 7, 7]               0
           Conv2d-85            [-1, 256, 7, 7]         589,824
      BatchNorm2d-86            [-1, 256, 7, 7]             512
             ReLU-87            [-1, 256, 7, 7]               0
           Conv2d-88            [-1, 256, 7, 7]         589,824
      BatchNorm2d-89            [-1, 256, 7, 7]             512
             ReLU-90            [-1, 256, 7, 7]               0
       BasicBlock-91            [-1, 256, 7, 7]               0
           Conv2d-92            [-1, 256, 7, 7]         589,824
      BatchNorm2d-93            [-1, 256, 7, 7]             512
             ReLU-94            [-1, 256, 7, 7]               0
           Conv2d-95            [-1, 256, 7, 7]         589,824
      BatchNorm2d-96            [-1, 256, 7, 7]             512
             ReLU-97            [-1, 256, 7, 7]               0
       BasicBlock-98            [-1, 256, 7, 7]               0
           Conv2d-99            [-1, 512, 4, 4]       1,179,648
     BatchNorm2d-100            [-1, 512, 4, 4]           1,024
            ReLU-101            [-1, 512, 4, 4]               0
          Conv2d-102            [-1, 512, 4, 4]       2,359,296
     BatchNorm2d-103            [-1, 512, 4, 4]           1,024
          Conv2d-104            [-1, 512, 4, 4]         131,072
     BatchNorm2d-105            [-1, 512, 4, 4]           1,024
            ReLU-106            [-1, 512, 4, 4]               0
      BasicBlock-107            [-1, 512, 4, 4]               0
          Conv2d-108            [-1, 512, 4, 4]       2,359,296
     BatchNorm2d-109            [-1, 512, 4, 4]           1,024
            ReLU-110            [-1, 512, 4, 4]               0
          Conv2d-111            [-1, 512, 4, 4]       2,359,296
     BatchNorm2d-112            [-1, 512, 4, 4]           1,024
            ReLU-113            [-1, 512, 4, 4]               0
      BasicBlock-114            [-1, 512, 4, 4]               0
          Conv2d-115            [-1, 512, 4, 4]       2,359,296
     BatchNorm2d-116            [-1, 512, 4, 4]           1,024
            ReLU-117            [-1, 512, 4, 4]               0
          Conv2d-118            [-1, 512, 4, 4]       2,359,296
     BatchNorm2d-119            [-1, 512, 4, 4]           1,024
            ReLU-120            [-1, 512, 4, 4]               0
      BasicBlock-121            [-1, 512, 4, 4]               0
AdaptiveAvgPool2d-122            [-1, 512, 1, 1]               0
          Linear-123                   [-1, 10]           5,130
================================================================
Total params: 21,280,970
Trainable params: 21,280,970
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.58
Params size (MB): 81.18
Estimated Total Size (MB): 101.77
----------------------------------------------------------------
